import argparse
from typing import Dict, Literal, List, Any, Tuple
import pandas as pd
from pathlib import Path
from sklearn.inspection import permutation_importance

from ASCOPD_model import DockerModelWrapper
from utils import is_between, load_csv, store_json


RANDOM_STATE = 2025


def pass_checks(
    tabular_data: pd.DataFrame,
    actual_target: pd.DataFrame,
    target_col: str,
) -> bool:
    """Validate that input DataFrames and required columns pass basic checks.

    Args:
        tabular_data (pd.DataFrame): The main tabular dataset.
        actual_target (pd.DataFrame): DataFrame containing the actual target values.
        target_col (str): The name of the target column that must exist in `actual_target`.

    Returns:
        bool: True if all checks pass, otherwise False.

    Checks performed:
        1. None of the inputs are None.
        2. None of the DataFrames are empty.
        3. DataFrames have the same length.
        4. `target_col` exists in `actual_target`.
    """

    if (tabular_data is None) or (actual_target is None):
        return False

    if tabular_data.empty or actual_target.empty:
        return False

    if not len(tabular_data) == len(actual_target):
        return False

    if target_col not in actual_target.columns:
        return False

    return True


def select_method(sens: float) -> Literal["feature_permutation", "baseline_occlusion"]:
    """
    Select an explainability method based on sensitivity level.
    Values < 0.5 -> "feature_permutation".
    Values >= 0.5 -> "baseline_occlusion".

    Args:
        sens (float): Sensitivity parameter in the range [0, 1].

    Returns:
        Literal["feature_permutation", "baseline_occlusion"]:
            The name of the selected explainability method.
    """

    return "feature_permutation" if sens < 0.5 else "baseline_occlusion"


def configure_model(
    target: Literal["VenDep", "ARF", "Mortality"],
) -> DockerModelWrapper:
    """
    Initialize and configure the Docker model wrapper for a specific target column.

    Args:
        target (Literal["VenDep", "ARF", "Mortality"]): The target column
            for which predictions will be generated by the Docker model.

    Returns:
        DockerModelWrapper: An instance of the Docker model wrapper configured.
    """

    return DockerModelWrapper(target=target)


def feature_permutation(
    X: pd.DataFrame, y: pd.DataFrame, target: str
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    Compute feature importance using permutation importance with a Dockerized model.
    This function wraps `sklearn.inspection.permutation_importance` to estimate how much
    each feature contributes to model performance. It uses the given target column to
    configure the model, evaluates feature importance with F1 scoring, and aggregates
    results across multiple repeats.

    Args:
        X (pd.DataFrame): Input features used for prediction.
        y (pd.DataFrame): True target values corresponding to `X`.
        target (str): Target column name used to configure the Dockerized model.

    Returns:
        Tuple[List[Dict[str, Any]], Dict[str, Any]]:
            - A list of dictionaries with feature names and their mean permutation importance.
              Example: `[{"Feature": "age", "Permutation_Importance": 0.12}, ...]`
            - A dictionary containing the full permutation importance results from sklearn,
              including per-repeat scores (`importances`), mean (`importances_mean`),
              and standard deviation (`importances_std`).
    """

    model = configure_model(target)

    importance_results = permutation_importance(
        estimator=model,
        X=X,
        y=y,
        scoring="f1",
        n_repeats=5,
        random_state=RANDOM_STATE,
        n_jobs=-1,
    )

    summary_results = list(
        map(
            lambda col, imp: {"Feature": col, "Permutation_Importance": imp},
            X.columns,
            importance_results.importances_mean,
        )
    )

    return summary_results, dict(importance_results)


def run_explainability_analysis(
    tabular_data, actual_target, target_col, output_dir, sensitivity
):

    # Init results
    results = [{}]
    output_dir.mkdir(parents=True, exist_ok=True)

    # Load data
    tabular_data = load_csv(tabular_data)
    actual_target = load_csv(actual_target)

    if not pass_checks(tabular_data, actual_target, target_col):
        return results

    method = select_method(sensitivity)
    print(f"Using method: {method} based on sensitivity: {sensitivity}")

    # Perform analysis
    if method == "feature_permutation":
        results, detailed_results = feature_permutation(
            X=tabular_data, y=actual_target, target=target_col
        )

    elif method == "baseline_occlusion":
        pass

    # Store results to output dir
    store_json(data=results, path=output_dir | f"{method}_analysis.json")
    store_json(
        data=detailed_results,
        path=output_dir | f"{method}_analysis_detailed_results.json",
    )


def main():
    parser = argparse.ArgumentParser(
        description="Analyze and explain feature importance"
    )

    parser.add_argument(
        "--tabular_data", required=True, help="Path to tabular data CSV file"
    )
    parser.add_argument(
        "--actual_target",
        required=True,
        help="Path to groundtruth target data CSV file",
    )
    parser.add_argument(
        "--target_col",
        required=True,
        choices=["VenDep", "ARF", "Mortality"],
        help="Name of target column name in actual and predicted target CSV file",
    )
    parser.add_argument(
        "--output",
        default="output",
        help="Output dir for results JSON files",
    )

    parser.add_argument(
        "--sensitivity",
        type=float,
        default=0.7,
        help="Sensitivity value (0-1): <0.5 uses permutation feature importance, >=0.5 uses baseline occlusion",
    )
    args = parser.parse_args()

    if not is_between(x=args.sensitivity):
        raise ValueError("Sensitivity must be between 0 and 1")

    run_explainability_analysis(
        tabular_data=args.tabular_data,
        actual_target=args.actual_target,
        target_col=args.target_col,
        output_dir=Path(args.output),
        sensitivity=args.sensitivity,
    )


if __name__ == "__main__":
    main()
